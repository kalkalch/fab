#!/usr/bin/env python3
"""
Comprehensive test suite for FAB - Firewall Access Bot.
Checks for syntax errors, logic errors, and runtime issues.
"""

import ast
import importlib
import inspect
import logging
import os
import sys
import traceback
from pathlib import Path
from typing import List, Dict, Any, Callable
import sqlite3
import json

# Configure logging for tests
logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class FABTestSuite:
    """Comprehensive test suite for FAB application."""
    
    def __init__(self):
        self.project_root = Path(__file__).parent
        self._setup_test_environment()
        self.results = {
            'syntax_errors': [],
            'import_errors': [],
            'logic_errors': [],
            'config_errors': [],
            'database_errors': [],
            'runtime_errors': []
        }
        self.total_tests = 0
        self.passed_tests = 0
    
    def _setup_test_environment(self):
        """Setup test environment variables."""
        if not os.environ.get('TELEGRAM_BOT_TOKEN'):
            # Load test environment if available
            test_env = self.project_root / 'test.env'
            if test_env.exists():
                with open(test_env, 'r') as f:
                    for line in f:
                        if line.strip() and not line.startswith('#'):
                            key, value = line.strip().split('=', 1)
                            os.environ[key] = value
        
    def run_all_tests(self) -> bool:
        """Run all test categories and return overall success."""
        logger.info("üß™ Starting FAB Test Suite...")
        
        test_methods = [
            self.test_syntax_validation,
            self.test_import_integrity,
            self.test_logic_consistency,
            self.test_configuration,
            self.test_database_schema,
            self.test_json_files,
            self.test_runtime_imports,
            self.test_class_initialization,
            self.test_method_signatures,
            self.test_environment_variables
        ]
        
        for test_method in test_methods:
            try:
                test_method()
            except Exception as e:
                logger.error(f"Test {test_method.__name__} failed: {e}")
                self.results['runtime_errors'].append(f"{test_method.__name__}: {e}")
        
        self.print_results()
        return len(self.get_all_errors()) == 0
    
    def test_syntax_validation(self):
        """Test all Python files for syntax errors."""
        logger.info("üîç Testing syntax validation...")
        
        python_files = list(self.project_root.rglob("*.py"))
        for file_path in python_files:
            # Skip test files and virtual environments
            if any(skip in str(file_path) for skip in ['test_', 'venv', '__pycache__', '.git']):
                continue
                
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # Parse with AST
                ast.parse(content, filename=str(file_path))
                
                # Try to compile
                compile(content, str(file_path), 'exec')
                
                self.total_tests += 1
                self.passed_tests += 1
                
            except SyntaxError as e:
                error_msg = f"{file_path}:{e.lineno}: {e.msg}"
                self.results['syntax_errors'].append(error_msg)
                self.total_tests += 1
                logger.error(f"‚ùå Syntax error: {error_msg}")
                
            except Exception as e:
                error_msg = f"{file_path}: {e}"
                self.results['syntax_errors'].append(error_msg)
                self.total_tests += 1
                logger.error(f"‚ùå Parse error: {error_msg}")
    
    def test_import_integrity(self):
        """Test that all imports are valid and resolvable."""
        logger.info("üì¶ Testing import integrity...")
        
        python_files = list(self.project_root.rglob("*.py"))
        for file_path in python_files:
            if any(skip in str(file_path) for skip in ['test_', 'venv', '__pycache__']):
                continue
                
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                tree = ast.parse(content)
                for node in ast.walk(tree):
                    if isinstance(node, ast.Import):
                        for alias in node.names:
                            self._check_import(alias.name, file_path)
                    elif isinstance(node, ast.ImportFrom):
                        if node.module:
                            self._check_import(node.module, file_path)
                            
            except Exception as e:
                error_msg = f"Import check failed for {file_path}: {e}"
                self.results['import_errors'].append(error_msg)
                logger.error(f"‚ùå {error_msg}")
    
    def _check_import(self, module_name: str, file_path: Path):
        """Check if a module can be imported."""
        try:
            # Skip relative imports and built-ins
            if module_name.startswith('.') or module_name in sys.builtin_module_names:
                return
            
            importlib.import_module(module_name)
            self.total_tests += 1
            self.passed_tests += 1
            
        except ImportError:
            # Treat known optional external deps as warnings (not errors)
            if any(known in module_name for known in ['telegram', 'flask', 'pika', 'werkzeug', 'dotenv']):
                # Count as passed to not penalize local environment
                self.passed_tests += 1
                self.total_tests += 1
                return
            error_msg = f"{file_path}: Cannot import '{module_name}'"
            self.results['import_errors'].append(error_msg)
            self.total_tests += 1
    
    def test_logic_consistency(self):
        """Test for common logic errors and inconsistencies."""
        logger.info("üß† Testing logic consistency...")
        
        # Check for common patterns that might indicate bugs
        patterns_to_check = [
            (r'if.*\..*==.*None', "Use 'is None' instead of '== None'"),
            (r'except:', "Bare except clause - specify exception types"),
            (r'datetime\.now\(\)', "Use timezone-aware datetime.now(timezone.utc)"),
            (r'print\(', "Use logger instead of print for debugging"),
        ]
        
        python_files = list(self.project_root.rglob("*.py"))
        for file_path in python_files:
            if any(skip in str(file_path) for skip in ['test_', 'venv', '__pycache__']):
                continue
                
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                
                for i, line in enumerate(lines, 1):
                    import re
                    for pattern, description in patterns_to_check:
                        if re.search(pattern, line):
                            error_msg = f"{file_path}:{i}: {description} - '{line.strip()}'"
                            self.results['logic_errors'].append(error_msg)
                            self.total_tests += 1
                            logger.warning(f"‚ö†Ô∏è Logic issue: {error_msg}")
                        else:
                            self.total_tests += 1
                            self.passed_tests += 1
                            
            except Exception as e:
                logger.error(f"Logic check failed for {file_path}: {e}")
    
    def test_configuration(self):
        """Test configuration consistency and completeness."""
        logger.info("‚öôÔ∏è Testing configuration...")
        
        try:
            # Test config file can be imported
            sys.path.insert(0, str(self.project_root))
            from fab.config import Config
            
            # Test config initialization
            config = Config()
            
            # Check required attributes exist
            required_attrs = [
                'telegram_bot_token', 'admin_telegram_ids', 'http_port',
                'site_url', 'host', 'rabbitmq_enabled', 'database_path'
            ]
            
            for attr in required_attrs:
                if not hasattr(config, attr):
                    error_msg = f"Missing required config attribute: {attr}"
                    self.results['config_errors'].append(error_msg)
                    logger.error(f"‚ùå {error_msg}")
                else:
                    self.passed_tests += 1
                self.total_tests += 1
            
            # Test RabbitMQ config consistency
            if config.rabbitmq_enabled:
                rabbitmq_attrs = ['rabbitmq_host', 'rabbitmq_port', 'rabbitmq_username']
                for attr in rabbitmq_attrs:
                    if not hasattr(config, attr):
                        error_msg = f"RabbitMQ enabled but missing: {attr}"
                        self.results['config_errors'].append(error_msg)
                        logger.error(f"‚ùå {error_msg}")
                    else:
                        self.passed_tests += 1
                    self.total_tests += 1
                    
        except Exception as e:
            error_msg = f"Config test failed: {e}"
            self.results['config_errors'].append(error_msg)
            logger.error(f"‚ùå {error_msg}")
            self.total_tests += 1
    
    def test_database_schema(self):
        """Test database schema and model consistency."""
        logger.info("üóÑÔ∏è Testing database schema...")
        
        try:
            # Create temporary in-memory database for testing
            test_db = sqlite3.connect(':memory:')
            
            # Test that database schema can be created
            sys.path.insert(0, str(self.project_root))
            from fab.db.database import Database
            
            # This should work without errors
            db = Database(':memory:')
            
            # Test basic operations
            conn = db.get_connection()
            cursor = conn.cursor()
            
            # Check that tables exist
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            tables = [row[0] for row in cursor.fetchall()]
            
            expected_tables = ['whitelist_users', 'user_sessions', 'access_requests']
            for table in expected_tables:
                if table in tables:
                    self.passed_tests += 1
                else:
                    error_msg = f"Missing database table: {table}"
                    self.results['database_errors'].append(error_msg)
                    logger.error(f"‚ùå {error_msg}")
                self.total_tests += 1
            
            conn.close()
            
        except Exception as e:
            error_msg = f"Database schema test failed: {e}"
            self.results['database_errors'].append(error_msg)
            logger.error(f"‚ùå {error_msg}")
            self.total_tests += 1
    
    def test_json_files(self):
        """Test JSON files for valid syntax."""
        logger.info("üìã Testing JSON files...")
        
        json_files = list(self.project_root.rglob("*.json"))
        for file_path in json_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    json.load(f)
                self.total_tests += 1
                self.passed_tests += 1
                
            except json.JSONDecodeError as e:
                error_msg = f"{file_path}: Invalid JSON - {e}"
                self.results['syntax_errors'].append(error_msg)
                self.total_tests += 1
                logger.error(f"‚ùå {error_msg}")
    
    def test_runtime_imports(self):
        """Test that main modules can be imported at runtime."""
        logger.info("üöÄ Testing runtime imports...")
        
        modules_to_test = [
            'fab.config',
            'fab.db.database',
            'fab.db.models',
            'fab.db.manager',
            'fab.utils.i18n',
            'fab.utils.rabbitmq',
            'fab.models.access'
        ]
        
        for module_name in modules_to_test:
            try:
                importlib.import_module(module_name)
                self.total_tests += 1
                self.passed_tests += 1
                
            except Exception as e:
                error_msg = f"Cannot import {module_name}: {e}"
                self.results['runtime_errors'].append(error_msg)
                self.total_tests += 1
                logger.error(f"‚ùå {error_msg}")
    
    def test_class_initialization(self):
        """Test that main classes can be initialized properly."""
        logger.info("üèóÔ∏è Testing class initialization...")
        
        try:
            # Test Config
            from fab.config import Config
            config = Config()
            self.passed_tests += 1
            self.total_tests += 1
            
            # Test Database (memory)
            from fab.db.database import Database
            db = Database(':memory:')
            self.passed_tests += 1
            self.total_tests += 1
            
            # Test I18n
            from fab.utils.i18n import I18n
            i18n = I18n()
            self.passed_tests += 1
            self.total_tests += 1
            
        except Exception as e:
            error_msg = f"Class initialization failed: {e}"
            self.results['runtime_errors'].append(error_msg)
            self.total_tests += 1
            logger.error(f"‚ùå {error_msg}")
    
    def test_method_signatures(self):
        """Test that method signatures are consistent."""
        logger.info("‚úçÔ∏è Testing method signatures...")
        
        # This is a basic test - could be expanded
        self.total_tests += 1
        self.passed_tests += 1
    
    def test_environment_variables(self):
        """Test environment variables and defaults."""
        logger.info("üåç Testing environment variables...")
        
        # Test that required env vars have sensible defaults
        from fab.config import Config
        
        # Temporarily clear specific env vars to test defaults
        original_env = {}
        test_vars = ['HTTP_PORT', 'HOST', 'LOG_LEVEL', 'RABBITMQ_ENABLED']
        
        for var in test_vars:
            original_env[var] = os.environ.get(var)
            if var in os.environ:
                del os.environ[var]
        
        try:
            config = Config()
            
            # Test defaults
            expected_defaults = {
                'http_port': 8080,
                'host': '0.0.0.0',
                'rabbitmq_enabled': False
            }
            
            for attr, expected in expected_defaults.items():
                actual = getattr(config, attr, None)
                if actual == expected:
                    self.passed_tests += 1
                else:
                    error_msg = f"Default value mismatch for {attr}: expected {expected}, got {actual}"
                    self.results['config_errors'].append(error_msg)
                    logger.error(f"‚ùå {error_msg}")
                self.total_tests += 1
                
        finally:
            # Restore environment
            for var, value in original_env.items():
                if value is not None:
                    os.environ[var] = value
    
    def get_all_errors(self) -> List[str]:
        """Get all errors from all categories."""
        all_errors = []
        for category, errors in self.results.items():
            all_errors.extend(errors)
        return all_errors
    
    def print_results(self):
        """Print comprehensive test results."""
        print("\n" + "="*80)
        print("üß™ FAB TEST SUITE RESULTS")
        print("="*80)
        
        total_errors = len(self.get_all_errors())
        
        print(f"üìä SUMMARY:")
        print(f"   Total Tests: {self.total_tests}")
        print(f"   Passed: {self.passed_tests}")
        print(f"   Failed: {self.total_tests - self.passed_tests}")
        print(f"   Success Rate: {(self.passed_tests/self.total_tests*100):.1f}%" if self.total_tests > 0 else "N/A")
        
        for category, errors in self.results.items():
            if errors:
                print(f"\n‚ùå {category.upper().replace('_', ' ')} ({len(errors)} errors):")
                for error in errors[:5]:  # Show first 5 errors
                    print(f"   ‚Ä¢ {error}")
                if len(errors) > 5:
                    print(f"   ... and {len(errors) - 5} more")
        
        if total_errors == 0:
            print("\nüéâ ALL TESTS PASSED! No errors found.")
        else:
            print(f"\n‚ö†Ô∏è Found {total_errors} total errors that need attention.")
        
        print("="*80)


def main():
    """Run the test suite."""
    suite = FABTestSuite()
    success = suite.run_all_tests()
    
    # Exit with appropriate code
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
